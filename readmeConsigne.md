# TP D√©tection de Lignes de Texte avec DBNet

## Objectif p√©dagogique

L'objectif de ce TP est de comprendre et impl√©menter un syst√®me de d√©tection de lignes de texte sur des images en utilisant un mod√®le de deep learning (DBNet) optimis√© pour le navigateur web. Vous allez travailler avec les technologies web modernes, le traitement d'images en temps r√©el, et l'inference de mod√®les ONNX.

## Contexte th√©orique

### DBNet : Diff√©renciable Binarisation Network

DBNet est un mod√®le de deep learning sp√©cialis√© dans la d√©tection de texte dans les images. Contrairement aux m√©thodes traditionnelles de binarisation (transformation d'une image en noir et blanc), DBNet apprend √† d√©tecter les contours de texte directement sans √©tape de post-traitement complexe.

**Architecture** :
- **Input** : Image RGB normalis√©e
- **Backbone** : R√©seau de convolution (ex: ResNet) pour extraire les caract√©ristiques
- **Neck** : Feature Pyramid Network (FPN) pour fusionner les features multi-√©chelles
- **Head** : G√©n√©ration de probabilit√©s pour chaque pixel (text/non-text)
- **Output** : Heatmap de probabilit√©s

### Pipeline de traitement

Le syst√®me se compose de trois √©tapes principales :

1. **Pr√©processing** : Adaptation de l'image pour le mod√®le
2. **Inference** : Ex√©cution du mod√®le ONNX
3. **Postprocessing** : Transformation de la heatmap en bo√Ætes de texte

## Structure du projet

```
tp-dbnet/
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ det_model.onnx      # Mod√®le DBNet pr√©-entra√Æn√©
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.ts                  # Interface utilisateur et gestion des √©v√©nements
‚îÇ   ‚îú‚îÄ‚îÄ postprocess.ts           # Rendu des r√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ worker/
‚îÇ       ‚îî‚îÄ‚îÄ dbnet.worker.ts      # Pipeline complet (pr√©processing, inference, postprocessing)
‚îú‚îÄ‚îÄ index.html                   # Interface web
‚îú‚îÄ‚îÄ package.json                 # D√©pendances du projet
‚îî‚îÄ‚îÄ tsconfig.json                # Configuration TypeScript
```

## Technologies utilis√©es

- **Vite** : Build tool moderne pour applications web
- **TypeScript** : Langage typ√© pour JavaScript
- **ONNX Runtime Web** : Ex√©cution de mod√®les ONNX dans le navigateur
- **OpenCV.js** : Biblioth√®que de traitement d'images (charg√©e via CDN)
- **Web Workers** : Traitement parall√®le pour ne pas bloquer l'interface

## Instructions de mise en place

### 1. Installation des d√©pendances

```bash
npm install
```

### 2. Lancement de l'application

```bash
npm run dev
```

L'application sera accessible sur `http://localhost:5173`

## Exercices pratiques

### Partie 1 : Comprendre le pr√©processing (30 min)

**Objectif** : Analyser et documenter l'√©tape de pr√©processing.

**Consignes** :
1. Ouvrez le fichier `src/worker/dbnet.worker.ts`
2. √âtudiez la fonction `preprocess()` (lignes 185-228)
3. R√©pondez aux questions suivantes :

   a) **Resize** : Pourquoi redimensionnons-nous l'image avec `RESIZE_MAX_SIDE = 960` ?
   
   b) **Padding** : Pourquoi ajoutons-nous du padding pour avoir des dimensions multiples de 32 ?
   
   c) **Normalisation** : 
      - Pourquoi divisons-nous par 255 les valeurs RGB ?
      - √Ä quoi correspondent les constantes `NORMALIZATION_MEAN` et `NORMALIZATION_STD` ?
   
   d) **Format du tensor** : Le tensor final est de format `[1, 3, H, W]`. Expliquez chaque dimension.

**Exercice pratique** : Modifiez la constante `RESIZE_MAX_SIDE` √† 480 pixels. Observez l'impact sur :
- La rapidit√© de traitement
- La qualit√© de d√©tection (pr√©cision des bo√Ætes)
- La m√©moire utilis√©e (inspectez dans les DevTools)

Documentez vos observations.

### Partie 2 : Analyser l'inference (20 min)

**Objectif** : Comprendre l'ex√©cution du mod√®le ONNX.

**Consignes** :
1. √âtudiez la fonction `runInference()` (lignes 251-297)
2. R√©pondez aux questions :

   a) Pourquoi le mod√®le est-il charg√© une seule fois et mis en cache ?
   
   b) Le mod√®le retourne une heatmap de probabilit√©s. Expliquez ce concept.
   
   c) Pourquoi avons-nous un fallback avec `images` comme nom d'entr√©e ?

**Note** : `onmessage` (ligne 453) est le point d'entr√©e du Web Worker. C'est ici que le pipeline complet est orchestr√©.

### Partie 3 : Ma√Ætriser le postprocessing (40 min)

**Objectif** : Impl√©menter et am√©liorer la d√©tection des lignes de texte.

**Consignes** :
1. √âtudiez la fonction `postprocess()` (lignes 338-444)
2. Tracez les √©tapes suivantes :

   a) **Binarisation** : 
      - Pourquoi multiplions-nous la heatmap par 255 ?
      - Que fait `cv.threshold()` avec `THRESH_BINARY` ?
      - Quel impact a la constante `THRESHOLD = 0.3` ?

   b) **Extraction des contours** :
      - √Ä quoi sert `cv.findContours()` ?
      - Pourquoi filtrons-nous les bo√Ætes avec `MIN_BOX_WIDTH` et `MIN_BOX_HEIGHT` ?

   c) **Regroupement par lignes** :
      - Expliquez l'algorithme de regroupement (lignes 398-434)
      - Comment est calcul√©e la `verticalTolerance` ?
      - Pourquoi trie-t-on les bo√Ætes par centre vertical puis par position horizontale ?

**Exercice pratique 1** : Modifiez le seuil `THRESHOLD` :
- Testez avec 0.1, 0.2, 0.4, 0.5
- Documentez pour chaque valeur :
  - Nombre de fausses d√©tections
  - Nombre de d√©tections manqu√©es
  - Coh√©rence visuelle des bo√Ætes

**Exercice pratique 2** : Impl√©mentez un filtrage suppl√©mentaire :
- Ajoutez un filtre qui supprime les bo√Ætes avec un ratio largeur/hauteur > 10
- Justifiez pourquoi ce filtre est pertinent
- Testez sur plusieurs images

**Exercice pratique 3** : Am√©liorez le regroupement par lignes :
- Actuellement, `verticalTolerance` est calcul√©e comme 15% de la hauteur moyenne
- Testez des valeurs de 10%, 20%, 25%
- √âvaluez l'impact sur des images avec des lignes irr√©guli√®res

### Partie 4 : Interface utilisateur (20 min)

**Objectif** : Interagir avec l'application et visualiser les r√©sultats.

**Consignes** :
1. √âtudiez `src/main.ts`
2. Comprenez le flux de donn√©es :
   - Comment l'image est-elle charg√©e ?
   - Comment est-elle envoy√©e au Web Worker ?
   - Comment les r√©sultats sont-ils affich√©s ?

3. Testez l'application avec diff√©rentes images :
   - Image avec texte horizontal
   - Image avec texte inclin√©
   - Image avec plusieurs paragraphes
   - Image avec du texte sur fond complexe

**Exercice pratique** : Ajoutez des statistiques :
- Nombre de lignes d√©tect√©es
- Temps de traitement (depuis l'envoi au worker jusqu'√† la r√©ception)
- Dimensions moyennes des lignes
- Affichez ces statistiques sous le JSON dans l'interface

### Partie 5 : Optimisations et d√©fis (bonus)

**Challenge 1** : Gestion des images de grande taille
- Actuellement, `RESIZE_MAX_SIDE = 960` peut √™tre limitant pour tr√®s grandes images
- Impl√©mentez un redimensionnement adaptatif qui :
  - Conserve les petites images (< 960px) √† leur taille originale
  - Redimensionne les grandes images tout en conservant le ratio
  - Testez sur des images de 2000x3000 pixels

**Challenge 2** : Gestion du texte inclin√©
- DBNet d√©tecte bien le texte horizontal
- Pour le texte inclin√©, il cr√©e des bo√Ætes englobantes rectangulaires
- Proposez une m√©thode pour d√©tecter l'angle d'inclinaison et roter les bo√Ætes

**Challenge 3** : WebGL backend
- Actuellement, ONNX Runtime utilise WASM
- CONFIGURE l'application pour utiliser WebGL (GPU)
  ```typescript
  executionProviders: ['webgl', 'wasm']
  ```
- Mesurez l'am√©lioration de performance

**Challenge 4** : Export des r√©sultats
- Impl√©mentez un bouton pour :
  - Exporter les images cropp√©es (une par ligne d√©tect√©e)
  - Exporter les coordonn√©es au format JSON, XML, ou CSV
  - Sauvegarder l'image originale avec les bo√Ætes dessin√©es

## Questions de synth√®se

1. **Architecture** : Pourquoi utilisons-nous un Web Worker plut√¥t que le thread principal pour l'inference ?

2. **Normalisation** : Les valeurs de normalisation ImageNet sont souvent utilis√©es dans les mod√®les pr√©-entra√Æn√©s. Expliquez pourquoi.

3. **Contraintes DBNet** : Pourquoi les dimensions doivent-elles √™tre multiples de 32 ? (Indice : pensez aux op√©rations de convolution et pooling)

4. **Complexit√©** : Calculez la complexit√© temporelle du postprocessing :
   - O(n) pour l'extraction des contours (n = nombre de pixels)
   - O(m log m) pour le tri (m = nombre de bo√Ætes)
   - O(m) pour le regroupement

5. **Robustesse** : Identifiez au moins 3 cas limites o√π le syst√®me pourrait √©chouer et proposez des solutions.

## Crit√®res d'√©valuation

- **Compr√©hension th√©orique** (30%) : R√©ponses pr√©cises aux questions
- **Code et impl√©mentation** (30%) : Modifications fonctionnelles et bien document√©es
- **Tests et observations** (20%) : Exp√©rimentations rigoureuses avec documentation
- **Bonus** (20%) : Challenges impl√©ment√©s et fonctionnels

## Ressources compl√©mentaires

- [Article original DBNet](https://arxiv.org/abs/1911.08947)
- [Documentation ONNX Runtime Web](https://onnxruntime.ai/docs/tutorials/web/)
- [OpenCV.js Reference](https://docs.opencv.org/4.x/d2/d00/tutorial_js_root.html)
- [Web Workers API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API)

## Dur√©e estim√©e

- Partie 1 : 30 minutes
- Partie 2 : 20 minutes
- Partie 3 : 40 minutes
- Partie 4 : 20 minutes
- Questions de synth√®se : 20 minutes
- Bonus : variable

**Total** : ~2h30 sans les bonus

## Remise du travail

1. Code comment√© avec vos modifications
2. Document PDF/Word contenant :
   - R√©ponses aux questions
   - Observations des exercices pratiques
   - Captures d'√©cran des tests
   - R√©sultats des challenges (si compl√©t√©s)
3. Archive ZIP avec l'ensemble du projet

**Note** : Le code doit compiler sans erreur et √™tre ex√©cutable avec `npm run dev`.

---

**Bonne chance dans votre apprentissage de la d√©tection de texte !** üìùü§ñ

